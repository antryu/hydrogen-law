"""
PDF íŒŒì¼ì—ì„œ ë²•ë ¹ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ RAG ì €ì¥
"""

import logging
import sys
import os
import re
from pathlib import Path
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

sys.path.insert(0, os.path.dirname(__file__))

from src.embeddings import KoreanEmbedder, LawChunker, LawChunk, VectorStore

try:
    import PyPDF2
except ImportError:
    print("âŒ PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜: pip install PyPDF2")
    sys.exit(1)


def extract_text_from_pdf(pdf_path: str) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            print(f"   ì´ {len(pdf_reader.pages)}í˜ì´ì§€")

            text_parts = []
            for page_num, page in enumerate(pdf_reader.pages, 1):
                page_text = page.extract_text()
                text_parts.append(page_text)

                if page_num % 10 == 0:
                    print(f"   ì§„í–‰: {page_num}/{len(pdf_reader.pages)} í˜ì´ì§€")

            return "\n".join(text_parts)
    except FileNotFoundError:
        logger.error(f"File not found: {pdf_path}")
        return ""
    except PyPDF2.errors.PdfReadError as e:
        logger.error(f"Failed to read PDF {pdf_path}: {e}")
        return ""
    except Exception as e:
        logger.error(f"Unexpected error reading {pdf_path}: {e}")
        return ""


def parse_law_text(text: str, law_name: str, law_id: str) -> List[Dict[str, Any]]:
    """ë²•ë ¹ í…ìŠ¤íŠ¸ë¥¼ ì¡°ë¬¸ ë‹¨ìœ„ë¡œ íŒŒì‹±"""

    # ì¡°ë¬¸ íŒ¨í„´: ì œ1ì¡°, ì œ2ì¡°, ì œ1ì¡°ì˜2 ë“± (ì œëª©ì´ ì—†ëŠ” ê²½ìš°ë„ í¬í•¨)
    article_pattern = re.compile(r"ì œ(\d+)ì¡°(?:ì˜\d+)?\s*(?:\(([^)]+)\))?")


    articles = []
    seen_articles = set()  # ì¤‘ë³µ ì œê±°ìš©
    matches = list(article_pattern.finditer(text))

    print(f"\n   ë°œê²¬ëœ ì¡°ë¬¸: {len(matches)}ê°œ")

    for i, match in enumerate(matches):
        article_number = f"ì œ{match.group(1)}ì¡°"
        title = match.group(2) or ""

        # ì¤‘ë³µ ì¡°ë¬¸ ê±´ë„ˆë›°ê¸°
        article_key = (law_id, article_number)
        if article_key in seen_articles:
            continue

        seen_articles.add(article_key)

        # ì¡°ë¬¸ ë‚´ìš©: í˜„ì¬ ì¡°ë¬¸ë¶€í„° ë‹¤ìŒ ì¡°ë¬¸ ì „ê¹Œì§€
        start = match.end()
        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)

        content = text[start:end].strip()

        # ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œì™¸
        if len(content) > 10:
            articles.append(
                {
                    "law_id": law_id,
                    "law_name": law_name,
                    "article_number": article_number,
                    "title": title,
                    "content": content[:2000],  # ìµœëŒ€ 2000ì
                }
            )

    return articles


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # PDF íŒŒì¼ ê²½ë¡œ
    pdf_dir = Path("/Users/andrew/Thairon/KGS")

    pdf_files = [
        {
            "path": pdf_dir / "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).pdf",
            "law_name": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²•",
            "law_id": "276461",
            "law_type": "ë²•ë¥ ",
        },
        {
            "path": pdf_dir
            / "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35803í˜¸)(20251001).pdf",
            "law_name": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²• ì‹œí–‰ë ¹",
            "law_id": "278293",
            "law_type": "ì‹œí–‰ë ¹",
        },
        {
            "path": pdf_dir
            / "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™(ì‚°ì—…í†µìƒë¶€ë ¹)(ì œ00001í˜¸)(20251001).pdf",
            "law_name": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™",
            "law_id": "278693",
            "law_type": "ì‹œí–‰ê·œì¹™",
        },
    ]

    print("=" * 60)
    print("PDF â†’ RAG ì €ì¥")
    print("=" * 60)

    all_chunks = []

    for pdf_info in pdf_files:
        print(f"\n{'='*60}")
        print(f"ğŸ“„ {pdf_info['law_name']}")
        print(f"{'='*60}")

        if not pdf_info["path"].exists():
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {pdf_info['path']}")
            continue

        # 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        print(f"\n1ï¸âƒ£ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
        text = extract_text_from_pdf(str(pdf_info["path"]))
        print(f"   âœ… {len(text)} ë¬¸ì ì¶”ì¶œ")

        # 2. ì¡°ë¬¸ íŒŒì‹±
        print(f"\n2ï¸âƒ£ ì¡°ë¬¸ íŒŒì‹± ì¤‘...")
        articles = parse_law_text(text, pdf_info["law_name"], pdf_info["law_id"])
        print(f"   âœ… {len(articles)}ê°œ ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ")

        # 3. ì²­í‚¹
        print(f"\n3ï¸âƒ£ ì²­í‚¹ ì¤‘...")
        chunker = LawChunker()

        for article in articles:
            chunks = chunker.chunk_article(
                law_id=article["law_id"],
                law_name=article["law_name"],
                article_number=article["article_number"],
                title=article["title"],
                content=article["content"],
            )
            all_chunks.extend(chunks)

        print(f"   âœ… {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± (ëˆ„ì )")

    # 4. ë²¡í„° DB ì €ì¥
    print(f"\n{'='*60}")
    print(f"4ï¸âƒ£ ë²¡í„° DB ì €ì¥ ì¤‘...")
    print(f"{'='*60}")

    embedder = KoreanEmbedder()
    vector_store = VectorStore(collection_name="hydrogen_law", embedder=embedder)

    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    vector_store.reset()

    # ì²­í¬ ì €ì¥
    vector_store.add_chunks(all_chunks)

    # í†µê³„
    stats = vector_store.get_stats()
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
    print(f"   ì´ ë¬¸ì„œ: {stats['total_documents']}ê°œ")
    print(f"   ì„ë² ë”© ì°¨ì›: {stats['embedding_dimension']}")

    # 5. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print(f"\n{'='*60}")
    print(f"5ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print(f"{'='*60}")

    test_query = "ê³ ì••ê°€ìŠ¤ ì œì¡° í—ˆê°€"
    print(f"\nğŸ” ì¿¼ë¦¬: '{test_query}'")

    results = vector_store.search(test_query, top_k=3)

    for i, result in enumerate(results, 1):
        print(
            f"\n{i}. {result['metadata']['law_name']} {result['metadata']['article_number']}"
        )
        print(f"   ì œëª©: {result['metadata']['title']}")
        print(f"   ìœ ì‚¬ë„: {result['similarity_score']:.3f}")
        print(f"   ë‚´ìš©: {result['content'][:100]}...")


if __name__ == "__main__":
    main()
