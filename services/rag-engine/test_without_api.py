"""
API í‚¤ ì—†ì´ í…ŒìŠ¤íŠ¸ - ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©

ì‹¤ì œ ë²•ë ¹ ë°ì´í„° êµ¬ì¡°ë¥¼ ì‹œë®¬ë ˆì´ì…˜
"""

import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))

from src.embeddings import KoreanEmbedder, LawChunker, LawChunk, VectorStore
from src.retrieval import HybridRetriever

# ìƒ˜í”Œ ë²•ë ¹ ë°ì´í„° (ì‹¤ì œ ë²•ë ¹ êµ¬ì¡°)
SAMPLE_LAWS = [
    {
        "law_id": "001234",
        "law_name": "ìˆ˜ì†Œê²½ì œ ìœ¡ì„± ë° ìˆ˜ì†Œ ì•ˆì „ê´€ë¦¬ì— ê´€í•œ ë²•ë¥ ",
        "article_number": "ì œ1ì¡°",
        "title": "ëª©ì ",
        "content": "ì´ ë²•ì€ ìˆ˜ì†Œê²½ì œ ìœ¡ì„±ê³¼ ìˆ˜ì†Œ ì•ˆì „ê´€ë¦¬ì— í•„ìš”í•œ ì‚¬í•­ì„ ê·œì •í•¨ìœ¼ë¡œì¨ ìˆ˜ì†Œê²½ì œë¡œì˜ ì „í™˜ì„ ì´‰ì§„í•˜ê³  ìˆ˜ì†Œì˜ ì•ˆì „í•œ ì‚¬ìš©ì„ ë„ëª¨í•˜ì—¬ êµ­ë¯¼ê²½ì œì˜ ì§€ì†ê°€ëŠ¥í•œ ë°œì „ê³¼ êµ­ë¯¼ì˜ ì•ˆì „ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤."
    },
    {
        "law_id": "001234",
        "law_name": "ìˆ˜ì†Œê²½ì œ ìœ¡ì„± ë° ìˆ˜ì†Œ ì•ˆì „ê´€ë¦¬ì— ê´€í•œ ë²•ë¥ ",
        "article_number": "ì œ18ì¡°",
        "title": "ìˆ˜ì†Œì¶©ì „ì†Œì˜ ì„¤ì¹˜Â·ìš´ì˜",
        "content": "ìˆ˜ì†Œì¶©ì „ì†Œë¥¼ ì„¤ì¹˜Â·ìš´ì˜í•˜ë ¤ëŠ” ìëŠ” ì‚°ì—…í†µìƒìì›ë¶€ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ì‹œÂ·ë„ì§€ì‚¬ì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•œë‹¤. ìˆ˜ì†Œì¶©ì „ì†Œì˜ ì‹œì„¤ê¸°ì¤€ ë° ê¸°ìˆ ê¸°ì¤€ì€ ì‚°ì—…í†µìƒìì›ë¶€ë ¹ìœ¼ë¡œ ì •í•œë‹¤."
    },
    {
        "law_id": "005678",
        "law_name": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²•",
        "article_number": "ì œ3ì¡°",
        "title": "ì •ì˜",
        "content": "ì´ ë²•ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 1. ê³ ì••ê°€ìŠ¤ë€ ì••ì¶•Â·ì•¡í™” ê·¸ ë°–ì˜ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ìƒìš©ì˜ ì˜¨ë„ì—ì„œ ì••ë ¥ì´ ëŒ€ê¸°ì••ì„ ì´ˆê³¼í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤."
    },
    {
        "law_id": "005678",
        "law_name": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²•",
        "article_number": "ì œ5ì¡°",
        "title": "ê³ ì••ê°€ìŠ¤ ì œì¡°ì˜ í—ˆê°€",
        "content": "ê³ ì••ê°€ìŠ¤ë¥¼ ì œì¡°í•˜ë ¤ëŠ” ìëŠ” ì‚°ì—…í†µìƒìì›ë¶€ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ì‹œÂ·ë„ì§€ì‚¬ì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•œë‹¤. ì œì¡°ì‹œì„¤ì˜ ì•ˆì „ê´€ë¦¬ì™€ ê²€ì‚¬ê¸°ì¤€ì€ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•œë‹¤."
    }
]

def test_chunking():
    """ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
    print("\n=== 1. ì²­í‚¹ í…ŒìŠ¤íŠ¸ ===")
    chunker = LawChunker(max_chunk_size=512, overlap=50)

    all_chunks = []
    for law in SAMPLE_LAWS:
        chunks = chunker.chunk_article(
            law_id=law["law_id"],
            law_name=law["law_name"],
            article_number=law["article_number"],
            title=law["title"],
            content=law["content"]
        )
        all_chunks.extend(chunks)

        print(f"âœ… {law['article_number']} {law['title']}: {len(chunks)}ê°œ ì²­í¬")

    print(f"\nì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
    return all_chunks

def test_embedding(chunks):
    """ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    print("\n=== 2. ì„ë² ë”© í…ŒìŠ¤íŠ¸ ===")
    print("í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")

    embedder = KoreanEmbedder()

    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_texts = [
        "ìˆ˜ì†Œì¶©ì „ì†Œ ì„¤ì¹˜ ê¸°ì¤€",
        "ê³ ì••ê°€ìŠ¤ ì•ˆì „ ê´€ë¦¬"
    ]

    embeddings = embedder.embed(test_texts)
    print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ")
    print(f"   ì°¨ì›: {embeddings.shape}")
    print(f"   ëª¨ë¸: {embedder.model_name}")

    return embedder

def test_vector_store(chunks, embedder):
    """ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸"""
    print("\n=== 3. ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ===")

    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vector_store = VectorStore(
        collection_name="test_hydrogen_law",
        persist_directory="./test_chroma_db",
        embedder=embedder
    )

    # ì´ˆê¸°í™”
    vector_store.reset()

    # ì²­í¬ ì¶”ê°€
    vector_store.add_chunks(chunks)

    # í†µê³„
    stats = vector_store.get_stats()
    print(f"âœ… ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ")
    print(f"   ì €ì¥ëœ ë¬¸ì„œ: {stats['total_documents']}ê°œ")
    print(f"   ì„ë² ë”© ì°¨ì›: {stats['embedding_dimension']}")

    return vector_store

def test_search(vector_store):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n=== 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ìˆ˜ì†Œì¶©ì „ì†Œ ì„¤ì¹˜ ê¸°ì¤€",
        "ê³ ì••ê°€ìŠ¤ ì•ˆì „",
        "ìˆ˜ì†Œ ì œì¡° í—ˆê°€"
    ]

    for query in test_queries:
        print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")

        results = vector_store.search(query, top_k=3)

        for i, result in enumerate(results, 1):
            print(f"   {i}. {result['metadata']['law_name']} {result['metadata']['article_number']}")
            print(f"      ìœ ì‚¬ë„: {result['similarity_score']:.3f}")
            print(f"      ë‚´ìš©: {result['content'][:80]}...")

def test_hybrid_search(vector_store, chunks):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n=== 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")

    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°
    retriever = HybridRetriever(vector_store)

    # BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
    documents = [
        {
            "id": chunk.chunk_id,
            "content": chunk.content,
            "metadata": {
                "law_name": chunk.law_name,
                "article_number": chunk.article_number,
                "title": chunk.title
            }
        }
        for chunk in chunks
    ]
    retriever.build_bm25_index(documents)

    # ê²€ìƒ‰
    query = "ìˆ˜ì†Œì¶©ì „ì†Œ ì„¤ì¹˜"
    print(f"\nğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: '{query}'")

    results = retriever.search(query, top_k=3)

    print(f"\nê²€ìƒ‰ ê²°ê³¼: {results['total_found']}ê±´")
    print(f"ê²€ìƒ‰ ì‹œê°„: {results['metadata']['search_time_ms']:.2f}ms")
    print(f"LLM ì‚¬ìš©: {results['metadata']['llm_used']}")

    for i, article in enumerate(results['articles'], 1):
        print(f"\n{i}. {article['law_name']} {article['article_number']}")
        print(f"   ì œëª©: {article['title']}")
        print(f"   ê´€ë ¨ë„: {article['relevance_score']:.2f}")
        print(f"   ë‚´ìš©: {article['content'][:100]}...")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ìˆ˜ì†Œë²•ë¥  RAG ì‹œìŠ¤í…œ - í†µí•© í…ŒìŠ¤íŠ¸ (API í‚¤ ì—†ìŒ)")
    print("=" * 60)

    try:
        # 1. ì²­í‚¹
        chunks = test_chunking()

        # 2. ì„ë² ë”©
        embedder = test_embedding(chunks)

        # 3. ë²¡í„° ìŠ¤í† ì–´
        vector_store = test_vector_store(chunks, embedder)

        # 4. ê²€ìƒ‰
        test_search(vector_store)

        # 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        test_hybrid_search(vector_store, chunks)

        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("=" * 60)

        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("1. API í‚¤ ë°œê¸‰: https://www.data.go.kr/data/15000115/openapi.do")
        print("2. export LAW_API_KEY='your_key'")
        print("3. ì‹¤ì œ ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
