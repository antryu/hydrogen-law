"""
ì‹¤ì œ ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° APIë¥¼ ì‚¬ìš©í•˜ì—¬
ê³ ì••ê°€ìŠ¤ë²• + ìˆ˜ì†Œë²• ìˆ˜ì§‘
"""

import sys
import os

sys.path.insert(0, os.path.dirname(__file__))

from src.collectors import LawAPIClient, LawParser
from src.embeddings import KoreanEmbedder, LawChunker, VectorStore

def collect_laws():
    """ë²•ë ¹ ìˆ˜ì§‘"""
    print("=" * 60)
    print("ì‹¤ì œ ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘")
    print("=" * 60)

    # API í´ë¼ì´ì–¸íŠ¸
    try:
        client = LawAPIClient()
        print(f"\nâœ… API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    except ValueError as e:
        print(f"\nâŒ {e}")
        return None

    # ìˆ˜ì§‘í•  ë²•ë ¹
    target_laws = [
        {
            "keyword": "ìˆ˜ì†Œê²½ì œ ìœ¡ì„± ë° ìˆ˜ì†Œ ì•ˆì „ê´€ë¦¬ì— ê´€í•œ ë²•ë¥ ",
            "short_name": "ìˆ˜ì†Œë²•"
        },
        {
            "keyword": "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬",
            "short_name": "ê³ ì••ê°€ìŠ¤ë²•"
        }
    ]

    all_laws = []

    for target in target_laws:
        print(f"\n{'='*60}")
        print(f"ğŸ” '{target['keyword']}' ê²€ìƒ‰ ì¤‘...")
        print(f"{'='*60}")

        # ê²€ìƒ‰
        laws = client.search_laws(target["keyword"], display=10)

        if not laws:
            print(f"âŒ '{target['keyword']}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            continue

        print(f"\nâœ… {len(laws)}ê°œ ë²•ë ¹ ë°œê²¬:")
        for i, law in enumerate(laws, 1):
            print(f"   {i}. {law.law_name} ({law.law_type})")
            print(f"      ID: {law.law_id}")
            print(f"      ì‹œí–‰ì¼: {law.enforcement_date}")

        # ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
        selected_law = laws[0]
        all_laws.append(selected_law)

        print(f"\nğŸ“¥ '{selected_law.law_name}' ìƒì„¸ ì¡°íšŒ ì¤‘...")

        # ìƒì„¸ ì •ë³´
        detail = client.get_law_detail(selected_law.law_id)

        if detail:
            articles = detail.get('articles', [])
            print(f"âœ… {len(articles)}ê°œ ì¡°ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ")

            # íŒŒì‹±
            parser = LawParser()
            parsed = parser.parse_from_api_response(detail)

            # ì²­í‚¹
            chunker = LawChunker()
            all_chunks = []

            for article in parsed.articles[:5]:  # ì²˜ìŒ 5ê°œ ì¡°ë¬¸ë§Œ í…ŒìŠ¤íŠ¸
                chunks = chunker.chunk_article(
                    law_id=parsed.law_id,
                    law_name=parsed.law_name,
                    article_number=article.article_number,
                    title=article.title,
                    content=article.content
                )
                all_chunks.extend(chunks)

            print(f"âœ… {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")

            # ë²¡í„° DB ì €ì¥
            print(f"\nğŸ’¾ ë²¡í„° DB ì €ì¥ ì¤‘...")

            embedder = KoreanEmbedder()
            vector_store = VectorStore(
                collection_name="hydrogen_law_real",
                embedder=embedder
            )

            vector_store.add_chunks(all_chunks)

            print(f"âœ… ì €ì¥ ì™„ë£Œ")

    print(f"\n{'='*60}")
    print(f"âœ… ë²•ë ¹ ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"   ìˆ˜ì§‘ëœ ë²•ë ¹: {len(all_laws)}ê°œ")
    print(f"{'='*60}")

    return all_laws

if __name__ == "__main__":
    collect_laws()
